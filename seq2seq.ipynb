{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhangtaiwei/htdocs/learning/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py:1711: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.util import nest\n",
    "\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_size = 1024 # Number of hidden units in each layer\n",
    "num_layers = 2 # Number of layers in each encoder and decoder\n",
    "embedding_size = 1024 # Embedding dimensions of encoder and decoder inputs\n",
    "learning_rate = 0.0001 # Learning rate\n",
    "batch_size = 128 # Batch size\n",
    "numEpochs = 30 # Maximum # of training epochs\n",
    "steps_per_checkpoint = 100 # Save model checkpoint every this iteration\n",
    "model_dir = 'model/'  # Path to save model checkpoints\n",
    "model_name = 'chatbot.ckpt'  # File name used for model checkpoints\n",
    "# word_to_idx = word_to_idx\n",
    "vocab_size = 20000 # len(word_to_idx)\n",
    "use_attention = True\n",
    "beam_search = True\n",
    "beam_size = 5\n",
    "max_gradient_norm = 5.0\n",
    "mode = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = tf.placeholder(tf.int32, [None, None], name='encoder_inputs')\n",
    "encoder_inputs_length = tf.placeholder(tf.int32, [None], name='encoder_inputs_length')\n",
    "\n",
    "batch_size = tf.placeholder(tf.int32, [], name='batch_size')\n",
    "keep_prob_placeholder = tf.placeholder(tf.float32, name='keep_prob_placeholder')\n",
    "\n",
    "decoder_targets = tf.placeholder(tf.int32, [None, None], name='decoder_targets')\n",
    "decoder_targets_length = tf.placeholder(tf.int32, [None], name='decoder_targets_length')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"encoder_inputs:0\", shape=(?, ?), dtype=int32)\n",
      "Tensor(\"encoder_inputs_length:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"batch_size:0\", shape=(), dtype=int32)\n",
      "Tensor(\"keep_prob_placeholder:0\", dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_inputs)\n",
    "print(encoder_inputs_length)\n",
    "print(batch_size)\n",
    "print(keep_prob_placeholder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sequence_mask example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False, False, False, False],\n",
       "       [ True,  True,  True, False, False],\n",
       "       [ True,  True, False, False, False]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 根据目标序列长度，选出其中最大值，然后使用该值构建序列长度的mask标志。用一个sequence_mask的例子来说明起作用\n",
    "tmp = tf.sequence_mask([1, 3, 2], 5)\n",
    "tmp.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"max_target_len:0\", shape=(), dtype=int32)\n",
      "Tensor(\"masks/Cast_1:0\", shape=(?, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "max_target_sequence_length = tf.reduce_max(decoder_targets_length, name='max_target_len')\n",
    "mask = tf.sequence_mask(decoder_targets_length, max_target_sequence_length, dtype=tf.float32, name='masks')\n",
    "print(max_target_sequence_length)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.rnn_cell_impl.MultiRNNCell at 0x116a93128>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _create_rnn_cell():\n",
    "    def single_rnn_cell():\n",
    "        # 创建单个cell，这里需要注意的是一定要使用一个single_rnn_cell的函数，不然直接把cell放在MultiRNNCell\n",
    "        # 的列表中最终模型会发生错误\n",
    "        single_cell = tf.contrib.rnn.LSTMCell(rnn_size)\n",
    "        #添加dropout\n",
    "        cell = tf.contrib.rnn.DropoutWrapper(single_cell, output_keep_prob=keep_prob_placeholder)\n",
    "        return cell\n",
    "    #列表中每个元素都是调用single_rnn_cell函数\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([single_rnn_cell() for _ in range(num_layers)])\n",
    "    return cell\n",
    "\n",
    "_create_rnn_cell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"encoder_2/rnn/transpose_1:0\", shape=(?, ?, 1024), dtype=float32)\n",
      "Tensor(\"encoder_inputs_length:0\", shape=(?,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('encoder', reuse=tf.AUTO_REUSE):\n",
    "    #创建LSTMCell，两层+dropout\n",
    "    encoder_cell = _create_rnn_cell()\n",
    "    #构建embedding矩阵,encoder和decoder公用该词向量矩阵\n",
    "    embedding = tf.get_variable('embedding', [vocab_size, embedding_size])\n",
    "    encoder_inputs_embedded = tf.nn.embedding_lookup(embedding, encoder_inputs)\n",
    "    # 使用dynamic_rnn构建LSTM模型，将输入编码成隐层向量。\n",
    "    # encoder_outputs用于attention，batch_size*encoder_inputs_length*rnn_size,\n",
    "    # encoder_state用于decoder的初始化状态，batch_size*rnn_szie\n",
    "    encoder_outputs, encoder_state = tf.nn.dynamic_rnn(encoder_cell, encoder_inputs_embedded,\n",
    "                                                       sequence_length=encoder_inputs_length,\n",
    "                                                       dtype=tf.float32)\n",
    "print(encoder_outputs)\n",
    "print(encoder_inputs_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  get_variable, embedding_lookup example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/zhangtaiwei/htdocs/learning/venv/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "[[0.57112493]\n",
      " [0.24146912]]\n",
      "[[0.61951534]\n",
      " [0.57112493]\n",
      " [0.24561572]\n",
      " [0.24146912]\n",
      " [0.6682324 ]\n",
      " [0.77851739]\n",
      " [0.98891948]\n",
      " [0.20760752]\n",
      " [0.46599252]\n",
      " [0.20757397]]\n",
      "[[-0.10204363 -0.8321332 ]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf;  \n",
    "import numpy as np;  \n",
    "  \n",
    "c = np.random.random([10,1])  \n",
    "b = tf.nn.embedding_lookup(c, [1, 3])  \n",
    "embeddingaa = tf.get_variable('embeddingaa', [1, 2])\n",
    "with tf.Session() as sess:  \n",
    "    sess.run(tf.initialize_all_variables())  \n",
    "    print(sess.run(b))\n",
    "    print(c)\n",
    "    print(embeddingaa.eval())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"tile_batch/Reshape:0\", shape=(?, ?, 1024), dtype=float32)\n",
      "Tensor(\"batch_size:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "encoder_outputs = tf.contrib.seq2seq.tile_batch(encoder_outputs, multiplier=beam_size)\n",
    "print(encoder_outputs)\n",
    "print(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tile_batch example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [0 1]\n",
      " [2 3]\n",
      " [2 3]\n",
      " [4 5]\n",
      " [4 5]\n",
      " [6 7]\n",
      " [6 7]\n",
      " [8 9]\n",
      " [8 9]]\n",
      "(10, 2)\n"
     ]
    }
   ],
   "source": [
    "a = np.array(range(10)).reshape(5,2)\n",
    "b = tf.contrib.seq2seq.tile_batch(a, 2)\n",
    "print(b.eval())\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stride_slice example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 1],\n",
       "        [2, 2]],\n",
       "\n",
       "       [[5, 5],\n",
       "        [6, 6]]], dtype=int32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[[1, 1, 1], [2, 2, 2]],\n",
    "            [[3, 3, 3], [4, 4, 4]],\n",
    "            [[5, 5, 5], [6, 6, 6]]]\n",
    "x = tf.strided_slice(data,[0,0,0],[3,2,2], [2,1,1])\n",
    "x.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [4, 5]], dtype=int32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = [[1, 2, 3], [4, 5, 6]]  \n",
    "t2 = [[7, 8, 9], [10, 11, 12]]  \n",
    "a = tf.concat([t1, t2], 1)\n",
    "ending = tf.strided_slice(t1, [0, 0], [2, -1], [1, 1])\n",
    "ending.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 5, 5],\n",
       "       [5, 5, 5]], dtype=int32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = [2,3]\n",
    "data = tf.fill(dim, 5)\n",
    "data.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seq2seq.TrainingHelper Explanatin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.46275363 0.64004472 0.2621695  0.78560965 0.47488735]\n",
      " [0.66606458 0.91754313 0.57360561 0.6296369  0.58354235]]\n",
      "[array([0.46275363, 0.66606458]), array([0.64004472, 0.91754313]), array([0.2621695 , 0.57360561]), array([0.78560965, 0.6296369 ]), array([0.47488735, 0.58354235])]\n"
     ]
    }
   ],
   "source": [
    "# Ref : https://stackoverflow.com/questions/42130491/batch-major-vs-time-major-lstm\n",
    "# axis 0: each batch\n",
    "# axis 1: each time steps of each batch\n",
    "# tf.contrib.seq2seq.TrainingHelper(time_major=False ...)\n",
    "# time_major=False would transpose matrix of batch_data\n",
    "# below is a toy example using unstack to show what happen in TrainingHelper\n",
    "# when time_major=False\n",
    "import tensorflow as tf\n",
    "batch_data = tf.constant(np.random.rand(10).reshape(2,5))\n",
    "e = tf.unstack(batch_data,axis=1)\n",
    "with tf.Session() as sess:\n",
    "    print(batch_data.eval())\n",
    "    print(sess.run(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identity Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(1.0)\n",
    "y = tf.Variable(0.0)\n",
    "x_plus_1 = tf.assign_add(x, 1)\n",
    "\n",
    "with tf.control_dependencies([x_plus_1]):\n",
    "    # indentity means assign x to y\n",
    "    y = tf.identity(x)\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "with tf.Session() as session:\n",
    "    init.run()\n",
    "    for i in range(5):\n",
    "        print(y.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'tensorflow.python.util.nest' from '/Users/zhangtaiwei/htdocs/learning/venv/lib/python3.6/site-packages/tensorflow/python/util/nest.py'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Variable decoder/memory_layer/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"/Users/zhangtaiwei/htdocs/learning/venv/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py\", line 215, in __init__\n    self.memory_layer(self._values) if self.memory_layer  # pylint: disable=not-callable\n  File \"/Users/zhangtaiwei/htdocs/learning/venv/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py\", line 555, in __init__\n    name=name)\n  File \"<ipython-input-94-ceba2e00287c>\", line 13, in <module>\n    memory_sequence_length=encoder_inputs_length)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-ceba2e00287c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#定义要使用的attention机制。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(num_units=rnn_size, memory=encoder_outputs,\n\u001b[0;32m---> 13\u001b[0;31m                                                              memory_sequence_length=encoder_inputs_length)\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;31m#attention_mechanism = tf.contrib.seq2seq.LuongAttention(num_units=rnn_size, memory=encoder_outputs, memory_sequence_length=encoder_inputs_length)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# 定义decoder阶段要是用的LSTMCell，然后为其封装attention wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/htdocs/learning/venv/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_units, memory, memory_sequence_length, normalize, probability_fn, score_mask_value, dtype, name)\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0mmemory_sequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemory_sequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0mscore_mask_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscore_mask_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m    556\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_units\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_units\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_normalize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/htdocs/learning/venv/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, query_layer, memory, probability_fn, memory_sequence_length, memory_layer, check_inner_dims_defined, score_mask_value, name)\u001b[0m\n\u001b[1;32m    213\u001b[0m           check_inner_dims_defined=check_inner_dims_defined)\n\u001b[1;32m    214\u001b[0m       self._keys = (\n\u001b[0;32m--> 215\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_layer\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m           else self._values)\n\u001b[1;32m    217\u001b[0m       self._batch_size = (\n",
      "\u001b[0;32m~/htdocs/learning/venv/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    697\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_shape'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0minput_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m           \u001b[0;31m# Note: not all sub-classes of Layer call Layer.__init__ (especially\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/htdocs/learning/venv/lib/python3.6/site-packages/tensorflow/python/layers/core.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    136\u001b[0m                                     \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                                     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                                     trainable=True)\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m       self.bias = self.add_variable('bias',\n",
      "\u001b[0;32m~/htdocs/learning/venv/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36madd_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner)\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m             partitioner=partitioner)\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minit_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/htdocs/learning/venv/lib/python3.6/site-packages/tensorflow/python/training/checkpointable.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    434\u001b[0m     new_variable = getter(\n\u001b[1;32m    435\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         **kwargs_for_getter)\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/htdocs/learning/venv/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m   1315\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m       constraint=constraint)\n\u001b[0m\u001b[1;32m   1318\u001b[0m get_variable_or_local_docstring = (\n\u001b[1;32m   1319\u001b[0m     \"\"\"%s\n",
      "\u001b[0;32m~/htdocs/learning/venv/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m   1077\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m           \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m           constraint=constraint)\n\u001b[0m\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m~/htdocs/learning/venv/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m    423\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m           \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m           constraint=constraint)\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m   def _get_partitioned_variable(\n",
      "\u001b[0;32m~/htdocs/learning/venv/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[1;32m    392\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m           use_resource=use_resource, constraint=constraint)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/htdocs/learning/venv/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[1;32m    731\u001b[0m                          \u001b[0;34m\"reuse=tf.AUTO_REUSE in VarScope? \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[0;32m--> 733\u001b[0;31m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    734\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable decoder/memory_layer/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"/Users/zhangtaiwei/htdocs/learning/venv/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py\", line 215, in __init__\n    self.memory_layer(self._values) if self.memory_layer  # pylint: disable=not-callable\n  File \"/Users/zhangtaiwei/htdocs/learning/venv/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py\", line 555, in __init__\n    name=name)\n  File \"<ipython-input-94-ceba2e00287c>\", line 13, in <module>\n    memory_sequence_length=encoder_inputs_length)\n"
     ]
    }
   ],
   "source": [
    "# =================================3, 定义模型的decoder部分\n",
    "with tf.variable_scope('decoder'):\n",
    "    print(nest)\n",
    "    if beam_search:\n",
    "        # 如果使用beam_search，则需要将encoder的输出进行tile_batch，其实就是复制beam_size份。\n",
    "        print(\"use beamsearch decoding..\")\n",
    "        encoder_outputs = tf.contrib.seq2seq.tile_batch(encoder_outputs, multiplier=beam_size)\n",
    "        encoder_state = nest.map_structure(lambda s: tf.contrib.seq2seq.tile_batch(s, beam_size), encoder_state)\n",
    "        encoder_inputs_length = tf.contrib.seq2seq.tile_batch(encoder_inputs_length, multiplier=beam_size)\n",
    "\n",
    "    #定义要使用的attention机制。\n",
    "    attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(num_units=rnn_size, memory=encoder_outputs,\n",
    "                                                             memory_sequence_length=encoder_inputs_length)\n",
    "    #attention_mechanism = tf.contrib.seq2seq.LuongAttention(num_units=rnn_size, memory=encoder_outputs, memory_sequence_length=encoder_inputs_length)\n",
    "    # 定义decoder阶段要是用的LSTMCell，然后为其封装attention wrapper\n",
    "    decoder_cell = _create_rnn_cell()\n",
    "    decoder_cell = tf.contrib.seq2seq.AttentionWrapper(cell=decoder_cell, attention_mechanism=attention_mechanism,\n",
    "                                                       attention_layer_size=rnn_size, name='Attention_Wrapper')\n",
    "    print(encoder_state)\n",
    "    #如果使用beam_seach则batch_size = batch_size * beam_size。因为之前已经复制过一次\n",
    "    batch_size = batch_size if not beam_search else batch_size * beam_size\n",
    "    #定义decoder阶段的初始化状态，直接使用encoder阶段的最后一个隐层状态进行赋值\n",
    "    decoder_initial_state = decoder_cell.zero_state(batch_size=batch_size, dtype=tf.float32).clone(cell_state=encoder_state)\n",
    "    output_layer = tf.layers.Dense(vocab_size, kernel_initializer=tf.truncated_normal_initializer(mean=0.0, stddev=0.1))\n",
    "\n",
    "    if mode == 'train':\n",
    "        # 定义decoder阶段的输入，其实就是在decoder的target开始处添加一个<go>,并删除结尾处的<end>,并进行embedding。\n",
    "        # decoder_inputs_embedded的shape为[batch_size, decoder_targets_length, embedding_size]\n",
    "        ending = tf.strided_slice(decoder_targets, [0, 0], [batch_size, -1], [1, 1])\n",
    "        decoder_input = tf.concat([tf.fill([batch_size, 1], word_to_idx['<go>']), ending], 1)\n",
    "        decoder_inputs_embedded = tf.nn.embedding_lookup(embedding, decoder_input)\n",
    "        #训练阶段，使用TrainingHelper+BasicDecoder的组合，这一般是固定的，当然也可以自己定义Helper类，实现自己的功能\n",
    "        training_helper = tf.contrib.seq2seq.TrainingHelper(inputs=decoder_inputs_embedded,\n",
    "                                                            sequence_length=decoder_targets_length,\n",
    "                                                            time_major=False, name='training_helper')\n",
    "        training_decoder = tf.contrib.seq2seq.BasicDecoder(cell=decoder_cell, helper=training_helper,\n",
    "                                                           initial_state=decoder_initial_state, output_layer=output_layer)\n",
    "        #调用dynamic_decode进行解码，decoder_outputs是一个namedtuple，里面包含两项(rnn_outputs, sample_id)\n",
    "        # rnn_output: [batch_size, decoder_targets_length, vocab_size]，保存decode每个时刻每个单词的概率，可以用来计算loss\n",
    "        # sample_id: [batch_size], tf.int32，保存最终的编码结果。可以表示最后的答案\n",
    "        decoder_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder=training_decoder,\n",
    "                                                                  impute_finished=True,\n",
    "                                                            maximum_iterations=max_target_sequence_length)\n",
    "        # 根据输出计算loss和梯度，并定义进行更新的AdamOptimizer和train_op\n",
    "        decoder_logits_train = tf.identity(decoder_outputs.rnn_output)\n",
    "        print(decoder_logits_train)\n",
    "        decoder_predict_train = tf.argmax(decoder_logits_train, axis=-1, name='decoder_pred_train')\n",
    "        # 使用sequence_loss计算loss，这里需要传入之前定义的mask标志\n",
    "        loss = tf.contrib.seq2seq.sequence_loss(logits=decoder_logits_train,\n",
    "                                                     targets=decoder_targets, weights=mask)\n",
    "\n",
    "        # Training summary for the current batch_loss\n",
    "        tf.summary.scalar('loss', loss)\n",
    "        summary_op = tf.summary.merge_all()\n",
    "\n",
    "        optimizer = tf.train.AdamOptimizer(learing_rate)\n",
    "        trainable_params = tf.trainable_variables()\n",
    "        gradients = tf.gradients(loss, trainable_params)\n",
    "        clip_gradients, _ = tf.clip_by_global_norm(gradients, max_gradient_norm)\n",
    "        train_op = optimizer.apply_gradients(zip(clip_gradients, trainable_params))\n",
    "    elif mode == 'decode':\n",
    "        start_tokens = tf.ones([batch_size, ], tf.int32) * word_to_idx['<go>']\n",
    "        end_token = word_to_idx['<eos>']\n",
    "        # decoder阶段根据是否使用beam_search决定不同的组合，\n",
    "        # 如果使用则直接调用BeamSearchDecoder（里面已经实现了helper类）\n",
    "        # 如果不使用则调用GreedyEmbeddingHelper+BasicDecoder的组合进行贪婪式解码\n",
    "        if beam_search:\n",
    "            inference_decoder = tf.contrib.seq2seq.BeamSearchDecoder(cell=decoder_cell, embedding=embedding,\n",
    "                                                                     start_tokens=start_tokens, end_token=end_token,\n",
    "                                                                     initial_state=decoder_initial_state,\n",
    "                                                                     beam_width=beam_size,\n",
    "                                                                     output_layer=output_layer)\n",
    "        else:\n",
    "            decoding_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(embedding=embedding,\n",
    "                                                                       start_tokens=start_tokens, end_token=end_token)\n",
    "            inference_decoder = tf.contrib.seq2seq.BasicDecoder(cell=decoder_cell, helper=decoding_helper,\n",
    "                                                                initial_state=decoder_initial_state,\n",
    "                                                                output_layer=output_layer)\n",
    "        decoder_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder=inference_decoder,\n",
    "                                                        maximum_iterations=10)\n",
    "        # 调用dynamic_decode进行解码，decoder_outputs是一个namedtuple，\n",
    "        # 对于不使用beam_search的时候，它里面包含两项(rnn_outputs, sample_id)\n",
    "        # rnn_output: [batch_size, decoder_targets_length, vocab_size]\n",
    "        # sample_id: [batch_size, decoder_targets_length], tf.int32\n",
    "\n",
    "        # 对于使用beam_search的时候，它里面包含两项(predicted_ids, beam_search_decoder_output)\n",
    "        # predicted_ids: [batch_size, decoder_targets_length, beam_size],保存输出结果\n",
    "        # beam_search_decoder_output: BeamSearchDecoderOutput instance namedtuple(scores, predicted_ids, parent_ids)\n",
    "        # 所以对应只需要返回predicted_ids或者sample_id即可翻译成最终的结果\n",
    "        if beam_search:\n",
    "            decoder_predict_decode = decoder_outputs.predicted_ids\n",
    "        else:\n",
    "            decoder_predict_decode = tf.expand_dims(decoder_outputs.sample_id, -1)\n",
    "# =================================4, 保存模型\n",
    "saver = tf.train.Saver(tf.global_variables())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "data_path = 'data/dataset-cornell-length10-filter1-vocabSize40000.pkl'\n",
    "data = pickle.load(open(data_path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['idCount', 'word2id', 'trainingSamples', 'id2word'])\n",
      "{}\n",
      "<class 'dict'> [('non-smoking', 23039), ('seducing', 12205), ('peux', 21580), ('c.p', 7696), ('cache', 16876), ('vitamins', 9025), ('vent', 10424), ('finish', 3606), ('drugstore', 4578), (\"g'head\", 17181)]\n",
      "\n",
      "[[['please', '.'], ['saturday', '?', 'night', '?']]]\n",
      "\n",
      "<class 'dict'> [(0, '<pad>'), (1, '<go>'), (2, '<eos>'), (3, '<unknown>'), (4, 'can'), (5, 'we'), (6, 'make'), (7, 'this'), (8, 'quick'), (9, '?')]\n"
     ]
    }
   ],
   "source": [
    "print(data.keys())\n",
    "print(data['idCount'])\n",
    "print(type(data['word2id']), list(data['word2id'].items())[:10])\n",
    "print()\n",
    "print([[[data['id2word'][i] for i in q], [data['id2word'][i] for i in a]] for q, a in data['trainingSamples'][:1]])\n",
    "print()\n",
    "print(type(data['id2word']), list(data['id2word'].items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
